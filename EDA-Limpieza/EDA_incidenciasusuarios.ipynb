{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. EDA\n",
    "En este apartado se pretende analizar los datasets para poder enfocar mejor la limpieza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Importación y carga de datos\n",
    "Debemos declarar las librerías que usamos y leer el correspondiente archivo de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación de librerías\n",
    "import pandas as pd\n",
    "\n",
    "# Lectura dataset\n",
    "df = pd.read_csv('../IncidenciasUsuariosSucio.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Configuración de Pandas\n",
    "Para poder leer bien los resultados de las ejecuciones, vamos a configurar tanto el número máximo de columnas como el número máximo de filas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Número máximo de filas a mostrar\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Número máximo de columnas a mostrar\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.width', 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Descripción general del dataset\n",
    "Para poder conocer ciertas características relevantes del dataset, como el número de instancias (filas) y características (columnas) procederemos a usar diferentes funciones de Pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 ID\n",
      "count  17633.000000\n",
      "mean    8814.868485\n",
      "std     5088.942963\n",
      "min        1.000000\n",
      "25%     4408.000000\n",
      "50%     8816.000000\n",
      "75%    13222.000000\n",
      "max    17628.000000\n",
      "\n",
      "\n",
      "Número de filas:  17633\n",
      "Número de columnas:  6\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17633 entries, 0 to 17632\n",
      "Data columns (total 6 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   ID               17633 non-null  int64 \n",
      " 1   TIPO_INCIDENCIA  17633 non-null  object\n",
      " 2   FECHA_REPORTE    17633 non-null  object\n",
      " 3   ESTADO           17633 non-null  object\n",
      " 4   UsuarioID        17633 non-null  object\n",
      " 5   MantenimeintoID  17633 non-null  object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 826.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Descripción de parámetros generales -> count, mean, std, min, 25%, 50%, 75%, max\n",
    "print(df.describe())\n",
    "\n",
    "# Número de filas y columnas del dataset\n",
    "print(\"\\n\")\n",
    "print(\"Número de filas: \", df.shape[0])\n",
    "print(\"Número de columnas: \", df.shape[1])\n",
    "print(\"\\n\")\n",
    "\n",
    "# Para saber el tipo de variable de cada columna\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Observación inicial del dataset\n",
    "Vamos a mostrar 30 entradas para poder observar cómo es realmente por dentro el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ----------    10 primeras filas    ----------    \n",
      "\n",
      "\n",
      "   ID     TIPO_INCIDENCIA FECHA_REPORTE   ESTADO                                      UsuarioID             MantenimeintoID\n",
      "0   1            Desgaste    04-06-2024  Cerrada                 ['877-15-7376', '467-34-2729']               ['MNT-13905']\n",
      "1   2            Desgaste    18-10-2023  Abierta                 ['592-42-6016', '339-07-9203']               ['MNT-00687']\n",
      "2   3              Rotura    27/07/2024  Cerrada                 ['012-65-0978', '976-02-8152']               ['MNT-00376']\n",
      "3   4          Vandalismo    12-25-2023  Cerrada  ['588-11-9551', '532-78-5662', '166-45-6290']               ['MNT-02131']\n",
      "4   5  Mal funcionamiento    01-14-2024  Cerrada                 ['004-60-5880', '563-73-1437']  ['MNT-05277', 'MNT-08362']\n",
      "5   6  Mal funcionamiento    16-06-2024  Cerrada                                ['243-58-3707']               ['MNT-00817']\n",
      "6   7  Mal funcionamiento    2023-11-29  Abierta                 ['568-97-1438', '060-60-3082']               ['MNT-13919']\n",
      "7   8            Desgaste    11/07/2024  Abierta                 ['796-05-5365', '885-57-6046']               ['MNT-12758']\n",
      "8   9  Mal funcionamiento    03-30-2024  Cerrada                 ['845-09-0809', '326-82-2881']               ['MNT-01303']\n",
      "9  10              Rotura    14-08-2024  Cerrada                                ['593-69-8841']               ['MNT-05048']\n",
      "\n",
      "\n",
      "   ----------    10 filas aleatorias    ----------    \n",
      "\n",
      "\n",
      "          ID     TIPO_INCIDENCIA FECHA_REPORTE   ESTADO                                      UsuarioID                          MantenimeintoID\n",
      "11279  11280              Rotura    2024-03-06  Abierta                                ['268-25-5422']                            ['MNT-01965']\n",
      "10849  10850  Mal funcionamiento    17/02/2024  Abierta                                ['752-12-9387']                            ['MNT-04534']\n",
      "16773  16774              Rotura    13-11-2023  Abierta                                ['588-27-3734']                            ['MNT-07103']\n",
      "16099  16100  Mal funcionamiento    06-05-2024  Abierta                                ['973-97-9814']                            ['MNT-06699']\n",
      "3129    3130          Vandalismo    2024-04-11  Cerrada                 ['291-81-2383', '821-21-6395']                            ['MNT-00453']\n",
      "12877  12878          Vandalismo    15-04-2024  Cerrada                                ['373-56-7422']                            ['MNT-03871']\n",
      "10298  10299            Desgaste    2023-11-20  Abierta                                ['788-59-4887']  ['MNT-08406', 'MNT-09228', 'MNT-10737']\n",
      "6240    6241          Vandalismo    07-25-2024  Abierta                                ['728-28-4364']                            ['MNT-13139']\n",
      "1862    1863            Desgaste    09-29-2024  Cerrada  ['433-99-2815', '899-03-9113', '734-10-7303']                            ['MNT-13477']\n",
      "7282    7283              Rotura    11-06-2024  Cerrada                                ['396-01-0573']                            ['MNT-02550']\n",
      "\n",
      "\n",
      "   ----------    10 últimas filas    ----------    \n",
      "\n",
      "\n",
      "          ID TIPO_INCIDENCIA FECHA_REPORTE   ESTADO                                      UsuarioID                          MantenimeintoID\n",
      "17623  17624          Rotura    03-10-2024  Abierta                                ['068-36-6972']                            ['MNT-09692']\n",
      "17624  17625      Vandalismo    11-17-2023  Cerrada                                ['488-16-1609']                            ['MNT-08294']\n",
      "17625  17626        Desgaste    15/12/2023  Cerrada                                ['463-41-5971']                            ['MNT-05830']\n",
      "17626  17627      Vandalismo    04-18-2024  Abierta                                ['108-96-7294']               ['MNT-09531', 'MNT-13463']\n",
      "17627  17628          Rotura    2024-09-12  Cerrada                                ['345-04-0305']                            ['MNT-13832']\n",
      "17628    431          Rotura    14/08/2024  Cerrada  ['122-92-6750', '293-31-6681', '599-62-2214']                            ['MNT-03964']\n",
      "17629  13905        Desgaste    09-08-2024  Cerrada                                ['853-84-5034']  ['MNT-04576', 'MNT-10566', 'MNT-11723']\n",
      "17630  12633      Vandalismo    02/12/2023  Cerrada                                ['903-64-1048']                            ['MNT-11152']\n",
      "17631   9948        Desgaste    04-03-2024  Cerrada                                ['722-68-2700']                            ['MNT-14428']\n",
      "17632  13653        Desgaste    04-12-2024  Cerrada                                ['992-49-1408']                            ['MNT-13712']\n"
     ]
    }
   ],
   "source": [
    "# Mostramos las 10 primeras filas, 10 filas aleatorias y las 10 últimas\n",
    "print(\"   ----------    10 primeras filas    ----------    \")\n",
    "print(\"\\n\")\n",
    "print(df.head(10))\n",
    "print(\"\\n\")\n",
    "print(\"   ----------    10 filas aleatorias    ----------    \")\n",
    "print(\"\\n\")\n",
    "print(df.sample(10))\n",
    "print(\"\\n\")\n",
    "print(\"   ----------    10 últimas filas    ----------    \")\n",
    "print(\"\\n\")\n",
    "print(df.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Revisión de valores nulos\n",
    "Como ya se ha visto en el anterior apartado (info), podemos observar los valores nulos de esa forma. Pero se puede observar de una forma más visual en esta sección y, además, hay que tener en cuenta valores como el cero que también pueden considerarse nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ----------    Valores faltantes    ----------    \n",
      "\n",
      "\n",
      "ID                 0\n",
      "TIPO_INCIDENCIA    0\n",
      "FECHA_REPORTE      0\n",
      "ESTADO             0\n",
      "UsuarioID          0\n",
      "MantenimeintoID    0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "    ----------    Valores cero    ----------    \n",
      "\n",
      "\n",
      "ID                 0\n",
      "TIPO_INCIDENCIA    0\n",
      "FECHA_REPORTE      0\n",
      "ESTADO             0\n",
      "UsuarioID          0\n",
      "MantenimeintoID    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Para poder saber el número de valores faltantes\n",
    "print(\"    ----------    Valores faltantes    ----------    \")\n",
    "print(\"\\n\")\n",
    "print(df.isnull().sum())\n",
    "print(\"\\n\")\n",
    "\n",
    "# Para poder saber el número de ceros en cada columna\n",
    "print(\"    ----------    Valores cero    ----------    \")\n",
    "print(\"\\n\")\n",
    "print((df == 0).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No existen valores nulos en este dataset, por lo que no se hará una limpieza de nulos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Identificación de fechas no estandarizadas\n",
    "Se deben identificar las fechas que no se encuentran en el formato adecuado para MongoDB (DD/MM/YYYY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ----------    Fechas    ----------    \n",
      "\n",
      "\n",
      "5025     2023-12-27\n",
      "15852    2024-08-01\n",
      "8873     28-08-2024\n",
      "2916     07-23-2024\n",
      "15833    2024-01-08\n",
      "3774     30/06/2024\n",
      "2932     2024-03-11\n",
      "4312     22/05/2024\n",
      "5286     2024-08-15\n",
      "13040    14/05/2024\n",
      "7423     19/02/2024\n",
      "3495     2024/09/08\n",
      "14269    30/10/2023\n",
      "5898     15-02-2024\n",
      "10435    2024/08/29\n",
      "6838     11-21-2023\n",
      "2876     11-05-2024\n",
      "10548    05-03-2024\n",
      "14158    20-11-2023\n",
      "7887     07-26-2024\n",
      "Name: FECHA_REPORTE, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Vamos a mostrar algunas fechas para poder observar en qué formato están\n",
    "print(\"   ----------    Fechas    ----------    \")\n",
    "print(\"\\n\")\n",
    "print(df['FECHA_REPORTE'].sample(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede apreciar, las fechas se encuentran en diversos formatos que deben ser homogeneizados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 Identificación de registros duplicados\n",
    "Debemos validar que no existen filas iguales que ensucien el dataset, sobre todo estando pendiente de duplicaciones de la clave primaria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ----------    Filas duplicadas    ----------    \n",
      "\n",
      "\n",
      "          ID TIPO_INCIDENCIA FECHA_REPORTE   ESTADO        UsuarioID MantenimeintoID\n",
      "17630  12633      Vandalismo    02/12/2023  Cerrada  ['903-64-1048']   ['MNT-11152']\n",
      "\n",
      "\n",
      "Número de filas duplicadas:  1\n",
      "\n",
      "\n",
      "   ----------    Filas con el mismo ID    ----------    \n",
      "\n",
      "\n",
      "          ID TIPO_INCIDENCIA FECHA_REPORTE   ESTADO                                      UsuarioID                          MantenimeintoID\n",
      "430      431          Rotura    08-14-2024  Cerrada  ['122-92-6750', '293-31-6681', '599-62-2214']                            ['MNT-03964']\n",
      "17628    431          Rotura    14/08/2024  Cerrada  ['122-92-6750', '293-31-6681', '599-62-2214']                            ['MNT-03964']\n",
      "9947    9948        Desgaste    03-04-2024  Cerrada                                ['722-68-2700']                            ['MNT-14428']\n",
      "17631   9948        Desgaste    04-03-2024  Cerrada                                ['722-68-2700']                            ['MNT-14428']\n",
      "17630  12633      Vandalismo    02/12/2023  Cerrada                                ['903-64-1048']                            ['MNT-11152']\n",
      "12632  12633      Vandalismo    02/12/2023  Cerrada                                ['903-64-1048']                            ['MNT-11152']\n",
      "17632  13653        Desgaste    04-12-2024  Cerrada                                ['992-49-1408']                            ['MNT-13712']\n",
      "13652  13653        Desgaste    12/04/2024  Cerrada                                ['992-49-1408']                            ['MNT-13712']\n",
      "17629  13905        Desgaste    09-08-2024  Cerrada                                ['853-84-5034']  ['MNT-04576', 'MNT-10566', 'MNT-11723']\n",
      "13904  13905        Desgaste    2024/08/09  Cerrada                                ['853-84-5034']  ['MNT-04576', 'MNT-10566', 'MNT-11723']\n",
      "\n",
      "\n",
      "Número de filas con el mismo ID:  10\n"
     ]
    }
   ],
   "source": [
    "# Ver las filas duplicadas\n",
    "print(\"   ----------    Filas duplicadas    ----------    \")\n",
    "print(\"\\n\")\n",
    "print(df[df.duplicated()])\n",
    "print(\"\\n\")\n",
    "# Número de filas duplicadas\n",
    "print(\"Número de filas duplicadas: \", df.duplicated().sum())\n",
    "print(\"\\n\")\n",
    "\n",
    "# Filtrar filas que tienen el mismo ID\n",
    "duplicados = df.groupby('ID').filter(lambda x: len(x) > 1)\n",
    "\n",
    "# Ordenar por NIF para que las filas con el mismo NIF se visualicen una encima de la otra\n",
    "duplicados = duplicados.sort_values(by='ID')\n",
    "\n",
    "# Mostrar las filas con la misma PK\n",
    "print(\"   ----------    Filas con el mismo ID    ----------    \")\n",
    "print(\"\\n\")\n",
    "print(duplicados)\n",
    "print(\"\\n\")\n",
    "print(\"Número de filas con el mismo ID: \", duplicados.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existen filas iguales que solo difieren en el formato de la fecha, por lo que se pueden considerar filas iguales que deberán ser eliminadas, ya que no aportan información adicional y solo ensucian el dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.8 Búsqueda de errores tipográficos\n",
    "Hay ciertos atributos de texto que pueden contar con determinados errores tipográficos que deben ser solucionados, como los nombres de áreas, juegos, usuarios y ubicaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este dataset no encontramos ningún atributo similar, por lo que este paso no se realizará"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.9 Identificación de valores enum fuera de campo\n",
    "Hay ciertos atributos que solo deben poseer ciertos valores (como Operativo-NoOperativo). Hace falta identificar aquellos valores de ese campo fuera de la norma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ----------    Valores distintos de la columna 'TIPO_INCIDENCIA'    ----------    \n",
      "\n",
      "\n",
      "['Desgaste' 'Rotura' 'Vandalismo' 'Mal funcionamiento']\n",
      "\n",
      "\n",
      "   ----------    Valores distintos de la columna 'ESTADO'    ----------    \n",
      "\n",
      "\n",
      "['Cerrada' 'Abierta']\n"
     ]
    }
   ],
   "source": [
    "# Muestra todos los valores distintos de la columna 'TIPO_INCIDENCIA'\n",
    "print(\"   ----------    Valores distintos de la columna 'TIPO_INCIDENCIA'    ----------    \")\n",
    "print(\"\\n\")\n",
    "print(df['TIPO_INCIDENCIA'].unique())\n",
    "print(\"\\n\")\n",
    "\n",
    "# Muestra todos los valores distintos de la columna 'ESTADO'\n",
    "print(\"   ----------    Valores distintos de la columna 'ESTADO'    ----------    \")\n",
    "print(\"\\n\")\n",
    "print(df['ESTADO'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todos los Enums poseen valores acordes con lo esperado, por lo que no se va a realizar una limpieza de ellos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.10 Validación de las coordenadas y otros campos geoespaciales\n",
    "Hay algunas veces en las que los códigos postales no respetan la identificación de Madrid (280..) o el formato, ya sean códigos postales u otros atributos de geolocalización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este dataset no encontramos valores de localización, por lo que este paso no se realizará"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.11 Identificación de unidades de medida en un formato no estandarizado\n",
    "Se deben identificar las filas que no posean un formato estándar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este dataset no encontramos valores de unidades de medida, por lo que este paso no se realizará"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.12 Otros atributos a corregir\n",
    "En esta sección se mencionarán aquellos atributos que también deban ser limpiados por errores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.12.1 Búsqueda de IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ----------    IDs    ----------    \n",
      "\n",
      "\n",
      "7161      7162\n",
      "6265      6266\n",
      "14954    14955\n",
      "3867      3868\n",
      "2477      2478\n",
      "7691      7692\n",
      "1278      1279\n",
      "15489    15490\n",
      "10080    10081\n",
      "11878    11879\n",
      "Name: ID, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Vamos a mostrar 10 IDs para ver cómo se encuentran\n",
    "print(\"   ----------    IDs    ----------    \")\n",
    "print(\"\\n\")\n",
    "print(df['ID'].sample(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a validar que los IDs son números enteros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ----------    Validación de ID    ----------    \n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'is_integer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   ----------    Validación de ID    ----------    \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mID\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_integer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mall())\n",
      "File \u001b[1;32mc:\\Users\\David\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4798\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4800\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4918\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4922\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m-> 4924\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\David\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\David\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[0;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\David\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\David\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1747\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[34], line 4\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   ----------    Validación de ID    ----------    \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_integer\u001b[49m())\u001b[38;5;241m.\u001b[39mall())\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'int' object has no attribute 'is_integer'"
     ]
    }
   ],
   "source": [
    "# Validar que todos los valores de ID sean enteros\n",
    "print(\"   ----------    Validación de ID    ----------    \")\n",
    "print(\"\\n\")\n",
    "print(df['ID'].apply(lambda x: x.is_integer()).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por ende, todos los IDs son válidos y no se deberán limpiar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.12.2 Validar todos los valores de la columna UsuarioID y MantenimientoID\n",
    "Hay que comprobar que todos los valores de estos campos siguen el formato de los ID de usuarios (XXX-XX-XXXX) sacado de Usuarios y de los IDs de mantenimiento, sacados de Mantenimiento. Además, debemos validar que todos los valores en ambas columnas están presentes en los otros datasets, para no estar referenciando a un valor que no existe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Todos los valores son IDs válidos de Usuarios:  True\n",
      "Todos los valores son IDs válidos de Mantenimiento:  True\n",
      "\n",
      "\n",
      "Todos los valores de UsuarioID y MantenimientoID se encuentran en los datasets correspondientes:  True\n"
     ]
    }
   ],
   "source": [
    "# Extraemos todos los valores del campo de 'UsuarioID' a una lista\n",
    "# Como todos están en formato string aunque parezcan listas, solo debemos eliminar los corchetes y las comillas y comas para colocarlo en una lista\n",
    "usuarios = df['UsuarioID'].tolist()\n",
    "usuarios = [x.replace('[', '').replace(']', '').replace(', ', '|').replace(\"'\", '') for x in usuarios]\n",
    "valido = True\n",
    "for elem in usuarios:\n",
    "    # Si el elemento posee un | hacer un split del |:\n",
    "    if '|' in elem:\n",
    "        lista = elem.split('|')\n",
    "        for e in lista:\n",
    "            # Si el elemento no tiene el formato \"XXX-XX-XXXX\", siendo X un número, entonces devuelve False\n",
    "            if not e[0:3].isdigit() or not e[4:6].isdigit() or not e[7:].isdigit(): \n",
    "                valido = False\n",
    "    else:\n",
    "        if not e[0:3].isdigit() or not e[4:6].isdigit() or not e[7:].isdigit():\n",
    "            valido = False\n",
    "print(\"Todos los valores son IDs válidos de Usuarios: \", valido)\n",
    "\n",
    "# Extraemos todos los valores del campo de 'MantenimientoID' a una lista\n",
    "# Como todos están en formato string aunque parezcan listas, solo debemos eliminar los corchetes y las comillas y comas para colocarlo en una lista\n",
    "mantenimiento = df['MantenimeintoID'].tolist()\n",
    "mantenimiento = [x.replace('[', '').replace(']', '').replace(', ', '|').replace(\"'\", '') for x in mantenimiento]\n",
    "valido = True\n",
    "for elem in mantenimiento:\n",
    "    # Si el elemento posee un | hacer un split del |:\n",
    "    if '|' in elem:\n",
    "        lista = elem.split('|')\n",
    "        for e in lista:\n",
    "            # Si el elemento no tiene el formato \"MNT-XXXXX\", siendo X un número, entonces devuelve False\n",
    "            if not e[0:4] == 'MNT-' or not e[4:].isdigit():\n",
    "                valido = False\n",
    "    else:\n",
    "        if not elem[0:4] == 'MNT-' or not elem[4:].isdigit():\n",
    "            print(elem)\n",
    "            print(elem[0:4])\n",
    "            print(elem[4:])\n",
    "            valido = False\n",
    "print(\"Todos los valores son IDs válidos de Mantenimiento: \", valido)\n",
    "print(\"\\n\")\n",
    "\n",
    "usuariosbis = df['UsuarioID'].tolist()\n",
    "usuarios_extraidos = []\n",
    "# Pasamos las listas de listas que se encuentren dentro de la lista a elementos individuales\n",
    "for elem in usuariosbis:\n",
    "    elem = elem.replace('[', '').replace(']', '').replace(', ', '|').replace(\"'\", '')\n",
    "    if '|' in elem:\n",
    "        lista = elem.split('|')\n",
    "        for e in lista:\n",
    "            usuarios_extraidos.append(e)\n",
    "    else:\n",
    "        usuarios_extraidos.append(elem)\n",
    "\n",
    "mantenimientobis = df['MantenimeintoID'].tolist()\n",
    "mantenimiento_extraidos = []\n",
    "# Pasamos las listas de listas que se encuentren dentro de la lista a elementos individuales\n",
    "for elem in mantenimientobis:\n",
    "    elem = elem.replace('[', '').replace(']', '').replace(', ', '|').replace(\"'\", '')\n",
    "    if '|' in elem:\n",
    "        lista = elem.split('|')\n",
    "        for e in lista:\n",
    "            mantenimiento_extraidos.append(e)\n",
    "    else:\n",
    "        mantenimiento_extraidos.append(elem)\n",
    "\n",
    "# Validar que todos los valores de UsuarioID y MantenimientoID se encuentren en UsuariosLimpio.csv y MantenimientoLimpio.csv\n",
    "usuarios = pd.read_csv('../UsuariosLimpio.csv')\n",
    "mantenimiento = pd.read_csv('../MantenimientoLimpio.csv')\n",
    "valido = True\n",
    "for elem in usuarios_extraidos:\n",
    "    if elem not in usuarios['NIF'].tolist():\n",
    "        valido = False\n",
    "for elem in mantenimiento_extraidos:\n",
    "    if elem not in mantenimiento['ID'].tolist():\n",
    "        valido = False\n",
    "print(\"Todos los valores de UsuarioID y MantenimientoID se encuentran en los datasets correspondientes: \", valido)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gracias al script anterior se puede observar como todos los IDs son válidos, tanto de mantenimiento como de usuario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.12.3 Consideraciones extras de Fechas\n",
    "Cabe recalcar que si el campo de fechas no posee un formato esperado, las funciones de limpieza darán error, por lo que no hace falta hacer ahora las comprobaciones de sus valores para determinar si son correctos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.12.4 Cambio de nombre columna de \"MantenimeintoID\" a \"MantenimientoID\"\n",
    "Esa columna posee una errata en su nombre que debe ser solucionada "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ID TIPO_INCIDENCIA FECHA_REPORTE   ESTADO        UsuarioID MantenimientoID\n",
      "14423  14424        Desgaste    13/11/2023  Cerrada  ['695-03-8864']   ['MNT-10121']\n"
     ]
    }
   ],
   "source": [
    "# Cambiar nombre de la columna \"MantenimeintoID\" a \"MantenimientoID\"\n",
    "df.rename(columns={'MantenimeintoID': 'MantenimientoID'}, inplace=True)\n",
    "\n",
    "# Mostramos el resultado del cambio con una muestra de 1 fila\n",
    "print(df.sample(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede observar, el nombre de la columna ha cambiado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Limpieza de los datasets\n",
    "En este apartado se realizará la limpieza según la información obtenida en el análisis exploratorio de datos:\n",
    "- Se deben eliminar las filas repetidas que no aportan más información\n",
    "- Se deben corregir las fechas y dejarlas en un formato estándar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Limpieza de filas repetidas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debemos eliminar las filas repetidas que no aportan información nueva. Para ello se va a eliminar una de las dos repetidas indistintivamente, ya que solo varían en el formato de la fecha, el resto de datos son iguales (incluso la fecha, solo que se encuentra en distinto formato y por eso Pandas lo reconoce como distinta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ----------    Filas con el mismo ID    ----------    \n",
      "\n",
      "\n",
      "          ID TIPO_INCIDENCIA FECHA_REPORTE   ESTADO                                      UsuarioID                          MantenimientoID\n",
      "430      431          Rotura    08-14-2024  Cerrada  ['122-92-6750', '293-31-6681', '599-62-2214']                            ['MNT-03964']\n",
      "17628    431          Rotura    14/08/2024  Cerrada  ['122-92-6750', '293-31-6681', '599-62-2214']                            ['MNT-03964']\n",
      "9947    9948        Desgaste    03-04-2024  Cerrada                                ['722-68-2700']                            ['MNT-14428']\n",
      "17631   9948        Desgaste    04-03-2024  Cerrada                                ['722-68-2700']                            ['MNT-14428']\n",
      "17630  12633      Vandalismo    02/12/2023  Cerrada                                ['903-64-1048']                            ['MNT-11152']\n",
      "12632  12633      Vandalismo    02/12/2023  Cerrada                                ['903-64-1048']                            ['MNT-11152']\n",
      "17632  13653        Desgaste    04-12-2024  Cerrada                                ['992-49-1408']                            ['MNT-13712']\n",
      "13652  13653        Desgaste    12/04/2024  Cerrada                                ['992-49-1408']                            ['MNT-13712']\n",
      "17629  13905        Desgaste    09-08-2024  Cerrada                                ['853-84-5034']  ['MNT-04576', 'MNT-10566', 'MNT-11723']\n",
      "13904  13905        Desgaste    2024/08/09  Cerrada                                ['853-84-5034']  ['MNT-04576', 'MNT-10566', 'MNT-11723']\n",
      "\n",
      "\n",
      "Número de filas con el mismo ID:  10\n",
      "\n",
      "\n",
      "   ----------    Filas con el mismo ID después de limpiar    ----------    \n",
      "\n",
      "\n",
      "Empty DataFrame\n",
      "Columns: [ID, TIPO_INCIDENCIA, FECHA_REPORTE, ESTADO, UsuarioID, MantenimientoID]\n",
      "Index: []\n",
      "\n",
      "\n",
      "Número de filas duplicadas:  0\n",
      "\n",
      "\n",
      "   ----------    2 filas de las que antes estaban duplicadas    ----------    \n",
      "\n",
      "\n",
      "      ID TIPO_INCIDENCIA FECHA_REPORTE   ESTADO                                      UsuarioID MantenimientoID\n",
      "430  431          Rotura    08-14-2024  Cerrada  ['122-92-6750', '293-31-6681', '599-62-2214']   ['MNT-03964']\n",
      "        ID TIPO_INCIDENCIA FECHA_REPORTE   ESTADO        UsuarioID MantenimientoID\n",
      "9947  9948        Desgaste    03-04-2024  Cerrada  ['722-68-2700']   ['MNT-14428']\n",
      "\n",
      "\n",
      "   ----------    Intento de acceder a una fila eliminada    ----------    \n",
      "\n",
      "\n",
      "Empty DataFrame\n",
      "Columns: [ID, TIPO_INCIDENCIA, FECHA_REPORTE, ESTADO, UsuarioID, MantenimientoID]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Filtrar filas que tienen el mismo ID\n",
    "duplicados = df.groupby('ID').filter(lambda x: len(x) > 1)\n",
    "\n",
    "# Ordenar por NIF para que las filas con el mismo ID se visualicen una encima de la otra\n",
    "duplicados = duplicados.sort_values(by='ID')\n",
    "\n",
    "# Mostrar las filas con la misma PK\n",
    "print(\"   ----------    Filas con el mismo ID    ----------    \")\n",
    "print(\"\\n\")\n",
    "print(duplicados)\n",
    "print(\"\\n\")\n",
    "print(\"Número de filas con el mismo ID: \", duplicados.shape[0])\n",
    "print(\"\\n\")\n",
    "\n",
    "# Limpiamos una de las dos filas con el mismo ID de duplicados\n",
    "df.drop_duplicates(subset='ID', keep='first', inplace=True)\n",
    "\n",
    "# Mostramos el resultado por pantalla\n",
    "print(\"   ----------    Filas con el mismo ID después de limpiar    ----------    \")\n",
    "print(\"\\n\")\n",
    "print(df[df.duplicated()])\n",
    "print(\"\\n\")\n",
    "# Número de filas duplicadas\n",
    "print(\"Número de filas duplicadas: \", df.duplicated().sum())\n",
    "print(\"\\n\")\n",
    "\n",
    "# Mostramos, para comprobar, 2 filas de las que antes estaban duplicadas\n",
    "print(\"   ----------    2 filas de las que antes estaban duplicadas    ----------    \")\n",
    "print(\"\\n\")\n",
    "print(df.loc[df['ID'] == 431])\n",
    "print(df.loc[df['ID'] == 9948])\n",
    "print(\"\\n\")\n",
    "\n",
    "# Mostramos el intento de acceder a una fila eliminada\n",
    "print(\"   ----------    Intento de acceder a una fila eliminada    ----------    \")\n",
    "print(\"\\n\")\n",
    "# Accedemos a la fila con ID 431 y FECHA_REPORTE 14/08/2024\n",
    "print(df.loc[(df['ID'] == 431) & (df['FECHA_REPORTE'] == '14/08/2024')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede apreciar que ya no hay filas duplicadas y que, si intentamos acceder a una fila de las repetidas y eliminadas, no podemos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Limpieza de FECHA_REPORTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debemos dejar las fechas en un formato estándar lejible por MongoDB, como 'DD/MM/YYYY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ----------    Columna de fechas corregidas    ----------    \n",
      "\n",
      "\n",
      "4883     08/12/2023\n",
      "14667    09/07/2024\n",
      "14       25/10/2023\n",
      "5323     21/08/2024\n",
      "48       08/10/2024\n",
      "9884     22/06/2024\n",
      "13799    25/01/2024\n",
      "388      19/04/2024\n",
      "7865     09/09/2024\n",
      "8670     01/12/2023\n",
      "16660    12/09/2024\n",
      "13596    06/07/2024\n",
      "10870    15/04/2024\n",
      "7683     13/01/2024\n",
      "1331     10/09/2024\n",
      "5462     10/02/2024\n",
      "10771    04/01/2024\n",
      "15913    11/07/2024\n",
      "9545     18/07/2024\n",
      "8449     28/10/2023\n",
      "Name: FECHA_REPORTE, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Leemos toda la columna de fechas y almacenamos todas las fechas en una lista\n",
    "fechas = df['FECHA_REPORTE'].tolist()\n",
    "\n",
    "# Ahora, pasamos por todas las fechas y corregimos las fechas que están mal escritas\n",
    "fechas_corregidas = []\n",
    "año_al_final = False\n",
    "\n",
    "for fecha in fechas:\n",
    "    # Si fecha contiene un guion, hacer fecha.split('-') y si fecha contiene una barra, hacer fecha.split('/')\n",
    "    if '-' in fecha:\n",
    "        fecha_split = fecha.split('-')\n",
    "    elif '/' in fecha:\n",
    "        fecha_split = fecha.split('/')\n",
    "    # Condiciones para saber el día, mes y año\n",
    "    # Encontrar el año\n",
    "    if (int(fecha_split[0])>31):\n",
    "        año = fecha_split[0]\n",
    "        año_al_final = False\n",
    "    elif (int(fecha_split[2])>31):\n",
    "        año = fecha_split[2]\n",
    "        año_al_final = True\n",
    "    else:\n",
    "        print(\"No se ha encontrado el año\")\n",
    "        fechas_corregidas.append(\"fecha incorrecta\")\n",
    "        break\n",
    "    # Encontrar el día y el mes\n",
    "    # Si el año está al final, no comprobamos el primer caracter\n",
    "    if año_al_final:\n",
    "        if (int(fecha_split[0])<32 and int(fecha_split[0])>12):\n",
    "            dia = fecha_split[0]\n",
    "            mes = fecha_split[1]\n",
    "        elif (int(fecha_split[1])<32 and int(fecha_split[1])>12):\n",
    "            dia = fecha_split[1]\n",
    "            mes = fecha_split[0]\n",
    "        # Si no hay ningun número entre el 13 y el 31, se asume que el mes es el segundo siempre y el día es el primero\n",
    "        else:\n",
    "            dia = fecha_split[0]\n",
    "            mes = fecha_split[1]\n",
    "    else:\n",
    "        if (int(fecha_split[1])<32 and int(fecha_split[1])>12):\n",
    "            dia = fecha_split[1]\n",
    "            mes = fecha_split[2]\n",
    "        elif (int(fecha_split[2])<32 and int(fecha_split[2])>12):\n",
    "            dia = fecha_split[2]\n",
    "            mes = fecha_split[1]\n",
    "        # Si no hay ningun número entre el 13 y el 31, se asume que el mes es el segundo siempre y el día es el tercero\n",
    "        else:\n",
    "            dia = fecha_split[2]\n",
    "            mes = fecha_split[1]\n",
    "    fechas_corregidas.append(dia+\"/\"+mes+\"/\"+año)\n",
    "    \n",
    "# Ahora, cambiamos toda la columna de FECHAS_INTERVENCION por las fechas corregidas\n",
    "df['FECHA_REPORTE'] = fechas_corregidas\n",
    "\n",
    "# Mostramos las fechas corregidas\n",
    "print(\"   ----------    Columna de fechas corregidas    ----------    \")\n",
    "print(\"\\n\")\n",
    "print(df['FECHA_REPORTE'].sample(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede apreciar, las fechas ya están estandarizadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Mostrar Dataset Limpio y guardar CSV\n",
    "Vamos a mostrar algunas filas del dataset limpio para validar que todo está OK y guardamos el Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ----------    10 filas aleatorias    ----------    \n",
      "\n",
      "\n",
      "          ID     TIPO_INCIDENCIA FECHA_REPORTE   ESTADO                                      UsuarioID MantenimientoID\n",
      "5327    5328              Rotura    31/12/2023  Abierta                                ['128-62-0893']   ['MNT-11157']\n",
      "2993    2994            Desgaste    20/06/2024  Cerrada                 ['232-12-9986', '224-13-0841']   ['MNT-13071']\n",
      "3968    3969              Rotura    29/02/2024  Cerrada                                ['015-95-0852']   ['MNT-02449']\n",
      "17193  17194          Vandalismo    07/03/2024  Cerrada                                ['412-53-5066']   ['MNT-12190']\n",
      "1824    1825          Vandalismo    21/12/2023  Cerrada                 ['902-99-9443', '991-47-6898']   ['MNT-08220']\n",
      "14256  14257              Rotura    03/01/2024  Cerrada                                ['990-70-1323']   ['MNT-08210']\n",
      "11376  11377          Vandalismo    13/08/2024  Cerrada                                ['036-42-1816']   ['MNT-04216']\n",
      "1676    1677          Vandalismo    21/09/2024  Abierta                 ['051-96-3483', '216-16-8942']   ['MNT-00984']\n",
      "3118    3119            Desgaste    14/06/2024  Cerrada  ['014-11-1873', '157-92-4447', '069-12-6973']   ['MNT-11118']\n",
      "15341  15342  Mal funcionamiento    25/07/2024  Cerrada                                ['676-96-4342']   ['MNT-08510']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Dataset limpio guardado\n"
     ]
    }
   ],
   "source": [
    "# Enseñamos 20 filas aleatorias para ver cómo quedan\n",
    "print(\"   ----------    10 filas aleatorias    ----------    \")\n",
    "print(\"\\n\")\n",
    "print(df.sample(10))\n",
    "print(\"\\n\")\n",
    "\n",
    "# Guardamos el dataset limpio\n",
    "df.to_csv('../IncidenciasUsuariosLimpio.csv', index=False)\n",
    "print(\"\\n\")\n",
    "print(\"Dataset limpio guardado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_MANTENIMIENTO = pd.read_csv('../MantenimientoLimpio.csv')\n",
    "juego_ids=[]\n",
    "for a in df['MantenimientoID']:\n",
    "    juego_id_encontrado = None\n",
    "    for index, b in enumerate(df_MANTENIMIENTO['ID']):\n",
    "        \n",
    "        if str(a[2:11])==str(b):\n",
    "            #añade una columna llamada JuegoID que tenga el valor de df_MANTENIMIENTO['JuegoID'] en la fila que estamos mirando\n",
    "            juego_id_encontrado = df_MANTENIMIENTO.loc[index, 'JuegoID']\n",
    "            \n",
    "            break\n",
    "    juego_ids.append(juego_id_encontrado)\n",
    "df['JuegoID'] = juego_ids\n",
    "print(df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
