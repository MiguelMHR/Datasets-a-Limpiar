{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. EDA\n",
    "En este apartado se pretende analizar los datasets para poder enfocar mejor la limpieza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Importación y carga de datos\n",
    "Debemos declarar las librerías que usamos y leer el correspondiente archivo de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación de librerías\n",
    "import pandas as pd\n",
    "\n",
    "# Lectura dataset\n",
    "df = pd.read_csv('../IncidenciasUsuariosSucio.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Configuración de Pandas\n",
    "Para poder leer bien los resultados de las ejecuciones, vamos a configurar tanto el número máximo de columnas como el número máximo de filas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Número máximo de filas a mostrar\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Número máximo de columnas a mostrar\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.width', 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Descripción general del dataset\n",
    "Para poder conocer ciertas características relevantes del dataset, como el número de instancias (filas) y características (columnas) procederemos a usar diferentes funciones de Pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 ID\n",
      "count  17633.000000\n",
      "mean    8814.868485\n",
      "std     5088.942963\n",
      "min        1.000000\n",
      "25%     4408.000000\n",
      "50%     8816.000000\n",
      "75%    13222.000000\n",
      "max    17628.000000\n",
      "\n",
      "\n",
      "Número de filas:  17633\n",
      "Número de columnas:  6\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17633 entries, 0 to 17632\n",
      "Data columns (total 6 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   ID               17633 non-null  int64 \n",
      " 1   TIPO_INCIDENCIA  17633 non-null  object\n",
      " 2   FECHA_REPORTE    17633 non-null  object\n",
      " 3   ESTADO           17633 non-null  object\n",
      " 4   UsuarioID        17633 non-null  object\n",
      " 5   MantenimeintoID  17633 non-null  object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 826.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Descripción de parámetros generales -> count, mean, std, min, 25%, 50%, 75%, max\n",
    "print(df.describe())\n",
    "\n",
    "# Número de filas y columnas del dataset\n",
    "print(\"\\n\")\n",
    "print(\"Número de filas: \", df.shape[0])\n",
    "print(\"Número de columnas: \", df.shape[1])\n",
    "print(\"\\n\")\n",
    "\n",
    "# Para saber el tipo de variable de cada columna\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Observación inicial del dataset\n",
    "Vamos a mostrar 30 entradas para poder observar cómo es realmente por dentro el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ----------    10 primeras filas    ----------    \n",
      "\n",
      "\n",
      "   ID     TIPO_INCIDENCIA FECHA_REPORTE   ESTADO                                      UsuarioID             MantenimeintoID\n",
      "0   1            Desgaste    04-06-2024  Cerrada                 ['877-15-7376', '467-34-2729']               ['MNT-13905']\n",
      "1   2            Desgaste    18-10-2023  Abierta                 ['592-42-6016', '339-07-9203']               ['MNT-00687']\n",
      "2   3              Rotura    27/07/2024  Cerrada                 ['012-65-0978', '976-02-8152']               ['MNT-00376']\n",
      "3   4          Vandalismo    12-25-2023  Cerrada  ['588-11-9551', '532-78-5662', '166-45-6290']               ['MNT-02131']\n",
      "4   5  Mal funcionamiento    01-14-2024  Cerrada                 ['004-60-5880', '563-73-1437']  ['MNT-05277', 'MNT-08362']\n",
      "5   6  Mal funcionamiento    16-06-2024  Cerrada                                ['243-58-3707']               ['MNT-00817']\n",
      "6   7  Mal funcionamiento    2023-11-29  Abierta                 ['568-97-1438', '060-60-3082']               ['MNT-13919']\n",
      "7   8            Desgaste    11/07/2024  Abierta                 ['796-05-5365', '885-57-6046']               ['MNT-12758']\n",
      "8   9  Mal funcionamiento    03-30-2024  Cerrada                 ['845-09-0809', '326-82-2881']               ['MNT-01303']\n",
      "9  10              Rotura    14-08-2024  Cerrada                                ['593-69-8841']               ['MNT-05048']\n",
      "\n",
      "\n",
      "   ----------    10 filas aleatorias    ----------    \n",
      "\n",
      "\n",
      "          ID     TIPO_INCIDENCIA FECHA_REPORTE   ESTADO                                      UsuarioID             MantenimeintoID\n",
      "16827  16828            Desgaste    12-27-2023  Cerrada                                ['480-04-8424']  ['MNT-03794', 'MNT-05200']\n",
      "6713    6714              Rotura    2024-05-13  Cerrada                                ['986-23-5569']               ['MNT-05030']\n",
      "12129  12130  Mal funcionamiento    12-02-2023  Cerrada                                ['565-80-7121']               ['MNT-06427']\n",
      "14722  14723            Desgaste    06/08/2024  Cerrada                                ['409-03-6491']               ['MNT-08775']\n",
      "13742  13743          Vandalismo    2024-09-02  Abierta                                ['583-43-0014']               ['MNT-07841']\n",
      "8024    8025            Desgaste    28/03/2024  Cerrada                                ['777-83-3865']               ['MNT-02713']\n",
      "7591    7592              Rotura    06-05-2024  Abierta                                ['887-52-7412']  ['MNT-00589', 'MNT-06885']\n",
      "5416    5417          Vandalismo    2024/04/01  Cerrada                                ['907-53-9503']               ['MNT-00055']\n",
      "15412  15413  Mal funcionamiento    30/05/2024  Cerrada                                ['793-26-0017']               ['MNT-10490']\n",
      "1288    1289            Desgaste    2024/06/06  Cerrada  ['057-33-1220', '950-40-5738', '423-30-7401']               ['MNT-01088']\n",
      "\n",
      "\n",
      "   ----------    10 últimas filas    ----------    \n",
      "\n",
      "\n",
      "          ID TIPO_INCIDENCIA FECHA_REPORTE   ESTADO                                      UsuarioID                          MantenimeintoID\n",
      "17623  17624          Rotura    03-10-2024  Abierta                                ['068-36-6972']                            ['MNT-09692']\n",
      "17624  17625      Vandalismo    11-17-2023  Cerrada                                ['488-16-1609']                            ['MNT-08294']\n",
      "17625  17626        Desgaste    15/12/2023  Cerrada                                ['463-41-5971']                            ['MNT-05830']\n",
      "17626  17627      Vandalismo    04-18-2024  Abierta                                ['108-96-7294']               ['MNT-09531', 'MNT-13463']\n",
      "17627  17628          Rotura    2024-09-12  Cerrada                                ['345-04-0305']                            ['MNT-13832']\n",
      "17628    431          Rotura    14/08/2024  Cerrada  ['122-92-6750', '293-31-6681', '599-62-2214']                            ['MNT-03964']\n",
      "17629  13905        Desgaste    09-08-2024  Cerrada                                ['853-84-5034']  ['MNT-04576', 'MNT-10566', 'MNT-11723']\n",
      "17630  12633      Vandalismo    02/12/2023  Cerrada                                ['903-64-1048']                            ['MNT-11152']\n",
      "17631   9948        Desgaste    04-03-2024  Cerrada                                ['722-68-2700']                            ['MNT-14428']\n",
      "17632  13653        Desgaste    04-12-2024  Cerrada                                ['992-49-1408']                            ['MNT-13712']\n"
     ]
    }
   ],
   "source": [
    "# Mostramos las 10 primeras filas, 10 filas aleatorias y las 10 últimas\n",
    "print(\"   ----------    10 primeras filas    ----------    \")\n",
    "print(\"\\n\")\n",
    "print(df.head(10))\n",
    "print(\"\\n\")\n",
    "print(\"   ----------    10 filas aleatorias    ----------    \")\n",
    "print(\"\\n\")\n",
    "print(df.sample(10))\n",
    "print(\"\\n\")\n",
    "print(\"   ----------    10 últimas filas    ----------    \")\n",
    "print(\"\\n\")\n",
    "print(df.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Revisión de valores nulos\n",
    "Como ya se ha visto en el anterior apartado (info), podemos observar los valores nulos de esa forma. Pero se puede observar de una forma más visual en esta sección y, además, hay que tener en cuenta valores como el cero que también pueden considerarse nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ----------    Valores faltantes    ----------    \n",
      "\n",
      "\n",
      "ID                 0\n",
      "TIPO_INCIDENCIA    0\n",
      "FECHA_REPORTE      0\n",
      "ESTADO             0\n",
      "UsuarioID          0\n",
      "MantenimeintoID    0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "    ----------    Valores cero    ----------    \n",
      "\n",
      "\n",
      "ID                 0\n",
      "TIPO_INCIDENCIA    0\n",
      "FECHA_REPORTE      0\n",
      "ESTADO             0\n",
      "UsuarioID          0\n",
      "MantenimeintoID    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Para poder saber el número de valores faltantes\n",
    "print(\"    ----------    Valores faltantes    ----------    \")\n",
    "print(\"\\n\")\n",
    "print(df.isnull().sum())\n",
    "print(\"\\n\")\n",
    "\n",
    "# Para poder saber el número de ceros en cada columna\n",
    "print(\"    ----------    Valores cero    ----------    \")\n",
    "print(\"\\n\")\n",
    "print((df == 0).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No existen valores nulos en este dataset, por lo que no se hará una limpieza de nulos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Identificación de fechas no estandarizadas\n",
    "Se deben identificar las fechas que no se encuentran en el formato adecuado para MongoDB (DD/MM/YYYY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ----------    Fechas    ----------    \n",
      "\n",
      "\n",
      "4418     2024/07/05\n",
      "3730     2024-07-08\n",
      "1240     2023-12-06\n",
      "14752    08-05-2024\n",
      "8554     14/06/2024\n",
      "9231     07-12-2023\n",
      "4871     2024/05/02\n",
      "5043     07-04-2024\n",
      "4415     24-11-2023\n",
      "17351    08/06/2024\n",
      "2056     10-09-2024\n",
      "11894    15/12/2023\n",
      "6197     11-13-2023\n",
      "1074     2023-10-25\n",
      "14530    2024/01/24\n",
      "5845     02-10-2024\n",
      "2809     02/09/2024\n",
      "15025    15-03-2024\n",
      "15803    2024/04/15\n",
      "1778     08-21-2024\n",
      "Name: FECHA_REPORTE, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Vamos a mostrar algunas fechas para poder observar en qué formato están\n",
    "print(\"   ----------    Fechas    ----------    \")\n",
    "print(\"\\n\")\n",
    "print(df['FECHA_REPORTE'].sample(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede apreciar, las fechas se encuentran en diversos formatos que deben ser homogeneizados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 Identificación de registros duplicados\n",
    "Debemos validar que no existen filas iguales que ensucien el dataset, sobre todo estando pendiente de duplicaciones de la clave primaria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ----------    Filas duplicadas    ----------    \n",
      "\n",
      "\n",
      "          ID TIPO_INCIDENCIA FECHA_REPORTE   ESTADO        UsuarioID MantenimeintoID\n",
      "17630  12633      Vandalismo    02/12/2023  Cerrada  ['903-64-1048']   ['MNT-11152']\n",
      "\n",
      "\n",
      "Número de filas duplicadas:  1\n",
      "\n",
      "\n",
      "   ----------    Filas con el mismo ID    ----------    \n",
      "\n",
      "\n",
      "          ID TIPO_INCIDENCIA FECHA_REPORTE   ESTADO                                      UsuarioID                          MantenimeintoID\n",
      "430      431          Rotura    08-14-2024  Cerrada  ['122-92-6750', '293-31-6681', '599-62-2214']                            ['MNT-03964']\n",
      "17628    431          Rotura    14/08/2024  Cerrada  ['122-92-6750', '293-31-6681', '599-62-2214']                            ['MNT-03964']\n",
      "9947    9948        Desgaste    03-04-2024  Cerrada                                ['722-68-2700']                            ['MNT-14428']\n",
      "17631   9948        Desgaste    04-03-2024  Cerrada                                ['722-68-2700']                            ['MNT-14428']\n",
      "17630  12633      Vandalismo    02/12/2023  Cerrada                                ['903-64-1048']                            ['MNT-11152']\n",
      "12632  12633      Vandalismo    02/12/2023  Cerrada                                ['903-64-1048']                            ['MNT-11152']\n",
      "17632  13653        Desgaste    04-12-2024  Cerrada                                ['992-49-1408']                            ['MNT-13712']\n",
      "13652  13653        Desgaste    12/04/2024  Cerrada                                ['992-49-1408']                            ['MNT-13712']\n",
      "17629  13905        Desgaste    09-08-2024  Cerrada                                ['853-84-5034']  ['MNT-04576', 'MNT-10566', 'MNT-11723']\n",
      "13904  13905        Desgaste    2024/08/09  Cerrada                                ['853-84-5034']  ['MNT-04576', 'MNT-10566', 'MNT-11723']\n",
      "\n",
      "\n",
      "Número de filas con el mismo ID:  10\n"
     ]
    }
   ],
   "source": [
    "# Ver las filas duplicadas\n",
    "print(\"   ----------    Filas duplicadas    ----------    \")\n",
    "print(\"\\n\")\n",
    "print(df[df.duplicated()])\n",
    "print(\"\\n\")\n",
    "# Número de filas duplicadas\n",
    "print(\"Número de filas duplicadas: \", df.duplicated().sum())\n",
    "print(\"\\n\")\n",
    "\n",
    "# Filtrar filas que tienen el mismo ID\n",
    "duplicados = df.groupby('ID').filter(lambda x: len(x) > 1)\n",
    "\n",
    "# Ordenar por NIF para que las filas con el mismo NIF se visualicen una encima de la otra\n",
    "duplicados = duplicados.sort_values(by='ID')\n",
    "\n",
    "# Mostrar las filas con la misma PK\n",
    "print(\"   ----------    Filas con el mismo ID    ----------    \")\n",
    "print(\"\\n\")\n",
    "print(duplicados)\n",
    "print(\"\\n\")\n",
    "print(\"Número de filas con el mismo ID: \", duplicados.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existen filas iguales que solo difieren en el formato de la fecha, por lo que se pueden considerar filas iguales que deberán ser eliminadas, ya que no aportan información adicional y solo ensucian el dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.8 Búsqueda de errores tipográficos\n",
    "Hay ciertos atributos de texto que pueden contar con determinados errores tipográficos que deben ser solucionados, como los nombres de áreas, juegos, usuarios y ubicaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este dataset no encontramos ningún atributo similar, por lo que este paso no se realizará"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.9 Identificación de valores enum fuera de campo\n",
    "Hay ciertos atributos que solo deben poseer ciertos valores (como Operativo-NoOperativo). Hace falta identificar aquellos valores de ese campo fuera de la norma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ----------    Valores distintos de la columna 'TIPO_INCIDENCIA'    ----------    \n",
      "\n",
      "\n",
      "['Desgaste' 'Rotura' 'Vandalismo' 'Mal funcionamiento']\n",
      "\n",
      "\n",
      "   ----------    Valores distintos de la columna 'ESTADO'    ----------    \n",
      "\n",
      "\n",
      "['Cerrada' 'Abierta']\n"
     ]
    }
   ],
   "source": [
    "# Muestra todos los valores distintos de la columna 'TIPO_INCIDENCIA'\n",
    "print(\"   ----------    Valores distintos de la columna 'TIPO_INCIDENCIA'    ----------    \")\n",
    "print(\"\\n\")\n",
    "print(df['TIPO_INCIDENCIA'].unique())\n",
    "print(\"\\n\")\n",
    "\n",
    "# Muestra todos los valores distintos de la columna 'ESTADO'\n",
    "print(\"   ----------    Valores distintos de la columna 'ESTADO'    ----------    \")\n",
    "print(\"\\n\")\n",
    "print(df['ESTADO'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todos los Enums poseen valores acordes con lo esperado, por lo que no se va a realizar una limpieza de ellos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.10 Validación de las coordenadas y otros campos geoespaciales\n",
    "Hay algunas veces en las que los códigos postales no respetan la identificación de Madrid (280..) o el formato, ya sean códigos postales u otros atributos de geolocalización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este dataset no encontramos valores de localización, por lo que este paso no se realizará"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.11 Identificación de unidades de medida en un formato no estandarizado\n",
    "Se deben identificar las filas que no posean un formato estándar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este dataset no encontramos valores de unidades de medida, por lo que este paso no se realizará"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.12 Otros atributos a corregir\n",
    "En esta sección se mencionarán aquellos atributos que también deban ser limpiados por errores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.12.1 Búsqueda de IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ----------    IDs    ----------    \n",
      "\n",
      "\n",
      "14385    14386\n",
      "2659      2660\n",
      "15509    15510\n",
      "4664      4665\n",
      "2488      2489\n",
      "15441    15442\n",
      "2169      2170\n",
      "16255    16256\n",
      "14009    14010\n",
      "8185      8186\n",
      "Name: ID, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Vamos a mostrar 10 IDs para ver cómo se encuentran\n",
    "print(\"   ----------    IDs    ----------    \")\n",
    "print(\"\\n\")\n",
    "print(df['ID'].sample(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a validar que los IDs son números enteros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ----------    Validación de ID    ----------    \n",
      "\n",
      "\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Validar que todos los valores de ID sean enteros\n",
    "print(\"   ----------    Validación de ID    ----------    \")\n",
    "print(\"\\n\")\n",
    "print(df['ID'].apply(lambda x: x.is_integer()).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por ende, todos los IDs son válidos y no se deberán limpiar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.12.2 Validar todos los valores de la columna UsuarioID y MantenimientoID\n",
    "Hay que comprobar que todos los valores de estos campos siguen el formato de los ID de usuarios (XXX-XX-XXXX) sacado de Usuarios y de los IDs de mantenimiento, sacados de Mantenimiento. Además, debemos validar que todos los valores en ambas columnas están presentes en los otros datasets, para no estar referenciando a un valor que no existe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Todos los valores son IDs válidos de Usuarios:  True\n",
      "Todos los valores son IDs válidos de Mantenimiento:  True\n",
      "\n",
      "\n",
      "Todos los valores de UsuarioID y MantenimientoID se encuentran en los datasets correspondientes:  True\n"
     ]
    }
   ],
   "source": [
    "# Extraemos todos los valores del campo de 'UsuarioID' a una lista\n",
    "# Como todos están en formato string aunque parezcan listas, solo debemos eliminar los corchetes y las comillas y comas para colocarlo en una lista\n",
    "usuarios = df['UsuarioID'].tolist()\n",
    "usuarios = [x.replace('[', '').replace(']', '').replace(', ', '|').replace(\"'\", '') for x in usuarios]\n",
    "valido = True\n",
    "for elem in usuarios:\n",
    "    # Si el elemento posee un | hacer un split del |:\n",
    "    if '|' in elem:\n",
    "        lista = elem.split('|')\n",
    "        for e in lista:\n",
    "            # Si el elemento no tiene el formato \"XXX-XX-XXXX\", siendo X un número, entonces devuelve False\n",
    "            if not e[0:3].isdigit() or not e[4:6].isdigit() or not e[7:].isdigit(): \n",
    "                valido = False\n",
    "    else:\n",
    "        if not e[0:3].isdigit() or not e[4:6].isdigit() or not e[7:].isdigit():\n",
    "            valido = False\n",
    "print(\"Todos los valores son IDs válidos de Usuarios: \", valido)\n",
    "\n",
    "# Extraemos todos los valores del campo de 'MantenimientoID' a una lista\n",
    "# Como todos están en formato string aunque parezcan listas, solo debemos eliminar los corchetes y las comillas y comas para colocarlo en una lista\n",
    "mantenimiento = df['MantenimeintoID'].tolist()\n",
    "mantenimiento = [x.replace('[', '').replace(']', '').replace(', ', '|').replace(\"'\", '') for x in mantenimiento]\n",
    "valido = True\n",
    "for elem in mantenimiento:\n",
    "    # Si el elemento posee un | hacer un split del |:\n",
    "    if '|' in elem:\n",
    "        lista = elem.split('|')\n",
    "        for e in lista:\n",
    "            # Si el elemento no tiene el formato \"MNT-XXXXX\", siendo X un número, entonces devuelve False\n",
    "            if not e[0:4] == 'MNT-' or not e[4:].isdigit():\n",
    "                valido = False\n",
    "    else:\n",
    "        if not elem[0:4] == 'MNT-' or not elem[4:].isdigit():\n",
    "            print(elem)\n",
    "            print(elem[0:4])\n",
    "            print(elem[4:])\n",
    "            valido = False\n",
    "print(\"Todos los valores son IDs válidos de Mantenimiento: \", valido)\n",
    "print(\"\\n\")\n",
    "\n",
    "usuariosbis = df['UsuarioID'].tolist()\n",
    "usuarios_extraidos = []\n",
    "# Pasamos las listas de listas que se encuentren dentro de la lista a elementos individuales\n",
    "for elem in usuariosbis:\n",
    "    elem = elem.replace('[', '').replace(']', '').replace(', ', '|').replace(\"'\", '')\n",
    "    if '|' in elem:\n",
    "        lista = elem.split('|')\n",
    "        for e in lista:\n",
    "            usuarios_extraidos.append(e)\n",
    "    else:\n",
    "        usuarios_extraidos.append(elem)\n",
    "\n",
    "mantenimientobis = df['MantenimeintoID'].tolist()\n",
    "mantenimiento_extraidos = []\n",
    "# Pasamos las listas de listas que se encuentren dentro de la lista a elementos individuales\n",
    "for elem in mantenimientobis:\n",
    "    elem = elem.replace('[', '').replace(']', '').replace(', ', '|').replace(\"'\", '')\n",
    "    if '|' in elem:\n",
    "        lista = elem.split('|')\n",
    "        for e in lista:\n",
    "            mantenimiento_extraidos.append(e)\n",
    "    else:\n",
    "        mantenimiento_extraidos.append(elem)\n",
    "\n",
    "# Validar que todos los valores de UsuarioID y MantenimientoID se encuentren en UsuariosLimpio.csv y MantenimientoLimpio.csv\n",
    "usuarios = pd.read_csv('../UsuariosLimpio.csv')\n",
    "mantenimiento = pd.read_csv('../MantenimientoLimpio.csv')\n",
    "valido = True\n",
    "for elem in usuarios_extraidos:\n",
    "    if elem not in usuarios['NIF'].tolist():\n",
    "        valido = False\n",
    "for elem in mantenimiento_extraidos:\n",
    "    if elem not in mantenimiento['ID'].tolist():\n",
    "        valido = False\n",
    "print(\"Todos los valores de UsuarioID y MantenimientoID se encuentran en los datasets correspondientes: \", valido)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gracias al script anterior se puede observar como todos los IDs son válidos, tanto de mantenimiento como de usuario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.12.3 Consideraciones extras de Fechas\n",
    "Cabe recalcar que si el campo de fechas no posee un formato esperado, las funciones de limpieza darán error, por lo que no hace falta hacer ahora las comprobaciones de sus valores para determinar si son correctos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.12.4 Cambio de nombre columna de \"MantenimeintoID\" a \"MantenimientoID\"\n",
    "Esa columna posee una errata en su nombre que debe ser solucionada "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ID TIPO_INCIDENCIA FECHA_REPORTE   ESTADO        UsuarioID             MantenimientoID\n",
      "17166  17167          Rotura    18-05-2024  Abierta  ['452-57-5193']  ['MNT-05293', 'MNT-08831']\n"
     ]
    }
   ],
   "source": [
    "# Cambiar nombre de la columna \"MantenimeintoID\" a \"MantenimientoID\"\n",
    "df.rename(columns={'MantenimeintoID': 'MantenimientoID'}, inplace=True)\n",
    "\n",
    "# Mostramos el resultado del cambio con una muestra de 1 fila\n",
    "print(df.sample(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede observar, el nombre de la columna ha cambiado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Limpieza de los datasets\n",
    "En este apartado se realizará la limpieza según la información obtenida en el análisis exploratorio de datos:\n",
    "- Se deben eliminar las filas repetidas que no aportan más información\n",
    "- Se deben corregir las fechas y dejarlas en un formato estándar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Limpieza de filas repetidas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debemos eliminar las filas repetidas que no aportan información nueva. Para ello se va a eliminar una de las dos repetidas indistintivamente, ya que solo varían en el formato de la fecha, el resto de datos son iguales (incluso la fecha, solo que se encuentra en distinto formato y por eso Pandas lo reconoce como distinta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ----------    Filas con el mismo ID    ----------    \n",
      "\n",
      "\n",
      "          ID TIPO_INCIDENCIA FECHA_REPORTE   ESTADO                                      UsuarioID                          MantenimientoID\n",
      "430      431          Rotura    08-14-2024  Cerrada  ['122-92-6750', '293-31-6681', '599-62-2214']                            ['MNT-03964']\n",
      "17628    431          Rotura    14/08/2024  Cerrada  ['122-92-6750', '293-31-6681', '599-62-2214']                            ['MNT-03964']\n",
      "9947    9948        Desgaste    03-04-2024  Cerrada                                ['722-68-2700']                            ['MNT-14428']\n",
      "17631   9948        Desgaste    04-03-2024  Cerrada                                ['722-68-2700']                            ['MNT-14428']\n",
      "17630  12633      Vandalismo    02/12/2023  Cerrada                                ['903-64-1048']                            ['MNT-11152']\n",
      "12632  12633      Vandalismo    02/12/2023  Cerrada                                ['903-64-1048']                            ['MNT-11152']\n",
      "17632  13653        Desgaste    04-12-2024  Cerrada                                ['992-49-1408']                            ['MNT-13712']\n",
      "13652  13653        Desgaste    12/04/2024  Cerrada                                ['992-49-1408']                            ['MNT-13712']\n",
      "17629  13905        Desgaste    09-08-2024  Cerrada                                ['853-84-5034']  ['MNT-04576', 'MNT-10566', 'MNT-11723']\n",
      "13904  13905        Desgaste    2024/08/09  Cerrada                                ['853-84-5034']  ['MNT-04576', 'MNT-10566', 'MNT-11723']\n",
      "\n",
      "\n",
      "Número de filas con el mismo ID:  10\n",
      "\n",
      "\n",
      "   ----------    Filas con el mismo ID después de limpiar    ----------    \n",
      "\n",
      "\n",
      "Empty DataFrame\n",
      "Columns: [ID, TIPO_INCIDENCIA, FECHA_REPORTE, ESTADO, UsuarioID, MantenimientoID]\n",
      "Index: []\n",
      "\n",
      "\n",
      "Número de filas duplicadas:  0\n",
      "\n",
      "\n",
      "   ----------    2 filas de las que antes estaban duplicadas    ----------    \n",
      "\n",
      "\n",
      "      ID TIPO_INCIDENCIA FECHA_REPORTE   ESTADO                                      UsuarioID MantenimientoID\n",
      "430  431          Rotura    08-14-2024  Cerrada  ['122-92-6750', '293-31-6681', '599-62-2214']   ['MNT-03964']\n",
      "        ID TIPO_INCIDENCIA FECHA_REPORTE   ESTADO        UsuarioID MantenimientoID\n",
      "9947  9948        Desgaste    03-04-2024  Cerrada  ['722-68-2700']   ['MNT-14428']\n",
      "\n",
      "\n",
      "   ----------    Intento de acceder a una fila eliminada    ----------    \n",
      "\n",
      "\n",
      "Empty DataFrame\n",
      "Columns: [ID, TIPO_INCIDENCIA, FECHA_REPORTE, ESTADO, UsuarioID, MantenimientoID]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Filtrar filas que tienen el mismo ID\n",
    "duplicados = df.groupby('ID').filter(lambda x: len(x) > 1)\n",
    "\n",
    "# Ordenar por NIF para que las filas con el mismo ID se visualicen una encima de la otra\n",
    "duplicados = duplicados.sort_values(by='ID')\n",
    "\n",
    "# Mostrar las filas con la misma PK\n",
    "print(\"   ----------    Filas con el mismo ID    ----------    \")\n",
    "print(\"\\n\")\n",
    "print(duplicados)\n",
    "print(\"\\n\")\n",
    "print(\"Número de filas con el mismo ID: \", duplicados.shape[0])\n",
    "print(\"\\n\")\n",
    "\n",
    "# Limpiamos una de las dos filas con el mismo ID de duplicados\n",
    "df.drop_duplicates(subset='ID', keep='first', inplace=True)\n",
    "\n",
    "# Mostramos el resultado por pantalla\n",
    "print(\"   ----------    Filas con el mismo ID después de limpiar    ----------    \")\n",
    "print(\"\\n\")\n",
    "print(df[df.duplicated()])\n",
    "print(\"\\n\")\n",
    "# Número de filas duplicadas\n",
    "print(\"Número de filas duplicadas: \", df.duplicated().sum())\n",
    "print(\"\\n\")\n",
    "\n",
    "# Mostramos, para comprobar, 2 filas de las que antes estaban duplicadas\n",
    "print(\"   ----------    2 filas de las que antes estaban duplicadas    ----------    \")\n",
    "print(\"\\n\")\n",
    "print(df.loc[df['ID'] == 431])\n",
    "print(df.loc[df['ID'] == 9948])\n",
    "print(\"\\n\")\n",
    "\n",
    "# Mostramos el intento de acceder a una fila eliminada\n",
    "print(\"   ----------    Intento de acceder a una fila eliminada    ----------    \")\n",
    "print(\"\\n\")\n",
    "# Accedemos a la fila con ID 431 y FECHA_REPORTE 14/08/2024\n",
    "print(df.loc[(df['ID'] == 431) & (df['FECHA_REPORTE'] == '14/08/2024')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede apreciar que ya no hay filas duplicadas y que, si intentamos acceder a una fila de las repetidas y eliminadas, no podemos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Limpieza de FECHA_REPORTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debemos dejar las fechas en un formato estándar lejible por MongoDB, como 'DD/MM/YYYY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ----------    Columna de fechas corregidas    ----------    \n",
      "\n",
      "\n",
      "1942     18/10/2023\n",
      "16577    08/11/2023\n",
      "1689     08/03/2024\n",
      "7144     03/12/2023\n",
      "12855    03/08/2024\n",
      "14459    07/10/2024\n",
      "14223    03/10/2024\n",
      "14276    02/04/2024\n",
      "7777     11/03/2024\n",
      "5343     28/02/2024\n",
      "9006     21/12/2023\n",
      "13286    27/06/2024\n",
      "11428    03/05/2024\n",
      "7886     25/06/2024\n",
      "15376    13/07/2024\n",
      "10257    02/08/2024\n",
      "3400     23/03/2024\n",
      "16439    30/08/2024\n",
      "2517     09/01/2024\n",
      "8582     23/10/2023\n",
      "Name: FECHA_REPORTE, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Leemos toda la columna de fechas y almacenamos todas las fechas en una lista\n",
    "fechas = df['FECHA_REPORTE'].tolist()\n",
    "\n",
    "# Ahora, pasamos por todas las fechas y corregimos las fechas que están mal escritas\n",
    "fechas_corregidas = []\n",
    "año_al_final = False\n",
    "\n",
    "for fecha in fechas:\n",
    "    # Si fecha contiene un guion, hacer fecha.split('-') y si fecha contiene una barra, hacer fecha.split('/')\n",
    "    if '-' in fecha:\n",
    "        fecha_split = fecha.split('-')\n",
    "    elif '/' in fecha:\n",
    "        fecha_split = fecha.split('/')\n",
    "    # Condiciones para saber el día, mes y año\n",
    "    # Encontrar el año\n",
    "    if (int(fecha_split[0])>31):\n",
    "        año = fecha_split[0]\n",
    "        año_al_final = False\n",
    "    elif (int(fecha_split[2])>31):\n",
    "        año = fecha_split[2]\n",
    "        año_al_final = True\n",
    "    else:\n",
    "        print(\"No se ha encontrado el año\")\n",
    "        fechas_corregidas.append(\"fecha incorrecta\")\n",
    "        break\n",
    "    # Encontrar el día y el mes\n",
    "    # Si el año está al final, no comprobamos el primer caracter\n",
    "    if año_al_final:\n",
    "        if (int(fecha_split[0])<32 and int(fecha_split[0])>12):\n",
    "            dia = fecha_split[0]\n",
    "            mes = fecha_split[1]\n",
    "        elif (int(fecha_split[1])<32 and int(fecha_split[1])>12):\n",
    "            dia = fecha_split[1]\n",
    "            mes = fecha_split[0]\n",
    "        # Si no hay ningun número entre el 13 y el 31, se asume que el mes es el segundo siempre y el día es el primero\n",
    "        else:\n",
    "            dia = fecha_split[0]\n",
    "            mes = fecha_split[1]\n",
    "    else:\n",
    "        if (int(fecha_split[1])<32 and int(fecha_split[1])>12):\n",
    "            dia = fecha_split[1]\n",
    "            mes = fecha_split[2]\n",
    "        elif (int(fecha_split[2])<32 and int(fecha_split[2])>12):\n",
    "            dia = fecha_split[2]\n",
    "            mes = fecha_split[1]\n",
    "        # Si no hay ningun número entre el 13 y el 31, se asume que el mes es el segundo siempre y el día es el tercero\n",
    "        else:\n",
    "            dia = fecha_split[2]\n",
    "            mes = fecha_split[1]\n",
    "    fechas_corregidas.append(dia+\"/\"+mes+\"/\"+año)\n",
    "    \n",
    "# Ahora, cambiamos toda la columna de FECHAS_INTERVENCION por las fechas corregidas\n",
    "df['FECHA_REPORTE'] = fechas_corregidas\n",
    "\n",
    "# Mostramos las fechas corregidas\n",
    "print(\"   ----------    Columna de fechas corregidas    ----------    \")\n",
    "print(\"\\n\")\n",
    "print(df['FECHA_REPORTE'].sample(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede apreciar, las fechas ya están estandarizadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Mostrar Dataset Limpio y guardar CSV\n",
    "Vamos a mostrar algunas filas del dataset limpio para validar que todo está OK y guardamos el Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ----------    10 filas aleatorias    ----------    \n",
      "\n",
      "\n",
      "          ID     TIPO_INCIDENCIA FECHA_REPORTE   ESTADO                                      UsuarioID                          MantenimientoID\n",
      "3453    3454            Desgaste    24/05/2024  Abierta                                ['591-78-5932']  ['MNT-02492', 'MNT-03711', 'MNT-11463']\n",
      "4364    4365              Rotura    23/07/2024  Cerrada  ['849-79-8851', '948-68-9260', '218-02-7266']                            ['MNT-10359']\n",
      "418      419            Desgaste    25/10/2023  Cerrada  ['764-34-5923', '564-49-2033', '060-85-1683']               ['MNT-08190', 'MNT-09211']\n",
      "15524  15525  Mal funcionamiento    08/01/2024  Abierta                                ['635-29-6405']                            ['MNT-11152']\n",
      "6680    6681              Rotura    22/05/2024  Abierta                                ['157-60-9878']                            ['MNT-10386']\n",
      "3499    3500              Rotura    21/10/2023  Cerrada                                ['451-44-3607']                            ['MNT-00626']\n",
      "11361  11362          Vandalismo    23/08/2024  Abierta                                ['120-54-4482']                            ['MNT-08950']\n",
      "17580  17581            Desgaste    02/12/2024  Abierta                                ['049-45-5944']               ['MNT-08333', 'MNT-13808']\n",
      "8749    8750  Mal funcionamiento    03/02/2024  Cerrada                                ['593-39-5914']                            ['MNT-00618']\n",
      "2414    2415              Rotura    16/10/2023  Cerrada  ['527-18-0212', '959-64-2679', '187-87-0352']                            ['MNT-00451']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Dataset limpio guardado\n"
     ]
    }
   ],
   "source": [
    "# Enseñamos 20 filas aleatorias para ver cómo quedan\n",
    "print(\"   ----------    10 filas aleatorias    ----------    \")\n",
    "print(\"\\n\")\n",
    "print(df.sample(10))\n",
    "print(\"\\n\")\n",
    "\n",
    "# Guardamos el dataset limpio\n",
    "df.to_csv('../IncidenciasUsuariosLimpio.csv', index=False)\n",
    "print(\"\\n\")\n",
    "print(\"Dataset limpio guardado\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
